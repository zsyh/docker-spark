version: "2"

services:
  zaizai-hadoop-1:
    image: zsyh/spark:2.1.1
    command: ["/usr/hadoop-2.7.3/etc/hadoop/master.sh"]
    hostname: zaizai-hadoop-1
    volumes:
      # - "./conf/hadoop:/usr/hadoop-2.7.3/etc/hadoop"
      # - "./conf/spark:/usr/spark-2.1.1/conf"
      - "/opt/hdfs:/opt/hdfs"
      - "/home/zaizai/data:/data"
    # extra_hosts:
    #   - "zaizai-hadoop-6:172.6.1.181"
    #   - "zaizai-hadoop-6.weave.local:172.6.1.181"
    network_mode: "weave"

  zaizai-hadoop-5:
    image: zsyh/spark:2.1.1
    command: ["/usr/hadoop-2.7.3/etc/hadoop/slave.sh"]
    hostname: zaizai-hadoop-5
    volumes:
      # - "./conf/hadoop:/usr/hadoop-2.7.3/etc/hadoop"
      # - "./conf/spark:/usr/spark-2.1.1/conf"
      - "/opt/hdfs1:/opt/hdfs"
    # environment:
    #   SPARK_WORKER_CORES: 4
    #   SPARK_WORKER_MEMORY: 3g
    # extra_hosts:
    #   - "zaizai-hadoop-1:172.6.1.100"
    network_mode: "weave"
    # links:
    #   - zaizai-hadoop-1


# deprecation
  # image: gettyimages/spark:2.1.1-hadoop-2.7
  # command: ["/usr/hadoop-2.7.3/sbin/hadoop-daemon.sh","start","namenode","&&","/usr/hadoop-2.7.3/sbin/yarn-daemon.sh","start","resourcemanager","&&"  ,"/usr/spark-2.1.1/bin/spark-class", "org.apache.spark.deploy.master.Master"]
  # command: ["/usr/spark-2.1.1/bin/spark-class", "org.apache.spark.deploy.master.Master"]

  # worker:
  #   image: singularities/spark
  #   command: start-spark worker master
  #   volumes:
  #     - "/opt/hdfs/worker:/opt/hdfs/worker"
  #   environment:
  #     SPARK_WORKER_CORES: 1
  #     SPARK_WORKER_MEMORY: 2g
  #   links:
  #     - master
